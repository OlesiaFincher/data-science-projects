{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: {sys.executable}: command not found\n",
      "/bin/bash: {sys.executable}: command not found\n"
     ]
    }
   ],
   "source": [
    "# установка spaCy\n",
    "# import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "#pip install spacy\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 21:27:00.682916: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных\n",
    "if os.path.exists('/datasets/toxic_comments.csv'):\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "else:\n",
    "    data = pd.read_csv('/Users/olesya/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и ознакомимся с ними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим текст от лишних символов. Оставим в датасете только регулярные выражения. Приведем текс к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция очистки текста методом re.sub()\n",
    "def clear_text(text):\n",
    "    sub = re.sub(r'[^a-z ]', ' ', text.lower())\n",
    "    #sub_split = sub.split()\n",
    "    new_text = \" \".join(sub.split())\n",
    "    return (new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# очищение текста от лишних символов\n",
    "data['clear_text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clear_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he matches this background colour i m se...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestions on impr...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка отработки метода\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим базу стоп-слов английского языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь очистим текст от стоп слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция очистки текста от стоп слов \n",
    "def remove_stop_words(text):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_comment = \" \".join([w for w in tokens if not w in stopwords])\n",
    "    return filtered_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# замена столбца clear_text новыми значениями\n",
    "data['clear_text'] = data['clear_text'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clear_text  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  aww matches background colour seemingly stuck ...  \n",
       "2  hey man really trying edit war guy constantly ...  \n",
       "3  make real suggestions improvement wondered sec...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка отработки метода\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем лемматизацию с помощью пакета Spacy Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция лемматизации способом spaCy\n",
    "def lemmatize(text):\n",
    "    sentence = nlp(text)\n",
    "    lemm_text = \" \".join([token.lemma_ for token in sentence])\n",
    "    \n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 36s, sys: 30.3 s, total: 15min 7s\n",
      "Wall time: 15min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['lemm_text_spacy'] = data['clear_text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>lemm_text_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "      <td>aww match background colour seemingly stick th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulations well use tools well talk</td>\n",
       "      <td>congratulation well use tool well talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "      <td>vandalism matt shirvington article revert plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry word nonsense offensive anyway intending...</td>\n",
       "      <td>sorry word nonsense offensive anyway intend wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  alignment on this subject and which are contra...      0   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  explanation edits made username hardcore metal...   \n",
       "1  aww matches background colour seemingly stuck ...   \n",
       "2  hey man really trying edit war guy constantly ...   \n",
       "3  make real suggestions improvement wondered sec...   \n",
       "4                      sir hero chance remember page   \n",
       "5           congratulations well use tools well talk   \n",
       "6                        cocksucker piss around work   \n",
       "7  vandalism matt shirvington article reverted pl...   \n",
       "8  sorry word nonsense offensive anyway intending...   \n",
       "9               alignment subject contrary dulithgow   \n",
       "\n",
       "                                     lemm_text_spacy  \n",
       "0  explanation edit make username hardcore metall...  \n",
       "1  aww match background colour seemingly stick th...  \n",
       "2  hey man really try edit war guy constantly rem...  \n",
       "3  make real suggestion improvement wonder sectio...  \n",
       "4                      sir hero chance remember page  \n",
       "5             congratulation well use tool well talk  \n",
       "6                        cocksucker piss around work  \n",
       "7  vandalism matt shirvington article revert plea...  \n",
       "8  sorry word nonsense offensive anyway intend wr...  \n",
       "9               alignment subject contrary dulithgow  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим лишние столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingly stick th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                    lemm_text_spacy\n",
       "0      0  explanation edit make username hardcore metall...\n",
       "1      0  aww match background colour seemingly stick th...\n",
       "2      0  hey man really try edit war guy constantly rem...\n",
       "3      0  make real suggestion improvement wonder sectio...\n",
       "4      0                      sir hero chance remember page"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удаление столбцов\n",
    "data = data.drop(['text', 'clear_text'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Комментарии были очищены от стоп-слов и лишних символов, приведены к леммам, затем удалены ненужные столбцы. Теперь можно перейти к обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели и сравним значение метрики качества F1. Рассмотрим три модели с различными гиперпараметрами. \n",
    "\n",
    "- LogisticRegression\n",
    "- DecisionTreeClassifier\n",
    "- CatboostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание итоговой таблицы\n",
    "results = pd.DataFrame(columns = ['model', 'F1 (train)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датасет на обучающую и тестовую выборки в пропорциях 70% и 30% соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# деление данных на обучающую и тестовую выборки\n",
    "train, test = train_test_split(data, test_size=0.30, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим признаки и целевой признак. Переменные для признаков преобразуем к нужному типу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание переменных для признаков и целевого признака\n",
    "features_train = train['lemm_text_spacy']\n",
    "target_train = train['toxic']\n",
    "features_test = test['lemm_text_spacy']\n",
    "target_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим TF-IDF для корпуса текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111699, 125205)\n",
      "(47872, 125205)\n",
      "(111699,)\n",
      "(47872,)\n"
     ]
    }
   ],
   "source": [
    "# создание признаков и целевого признака\n",
    "tfidf_train = count_tfidf.fit_transform(features_train) \n",
    "tfidf_test = count_tfidf.transform(features_test) \n",
    "\n",
    "print(tfidf_train.shape)\n",
    "print(tfidf_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe_lr = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        # ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LogisticRegression(random_state=12345))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lr = {'clf__class_weight':['balanced'],\n",
    "            'clf__C':[10,100],\n",
    "            'clf__solver':['liblinear'],\n",
    "            'clf__max_iter':[50,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие гиперпараметры модели: {'clf__C': 10, 'clf__class_weight': 'balanced', 'clf__max_iter': 50, 'clf__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# обучение модели\n",
    "grid_lr = GridSearchCV(pipe_lr, param_grid=param_lr, scoring='f1', cv = 3, n_jobs=-1)\n",
    "\n",
    "grid_lr.fit(features_train, target_train) # tfidf_train\n",
    "#predict_train_lr = grid_lr.predict(tfidf_train)\n",
    "print('Наилучшие гиперпараметры модели:', grid_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика логистической регрессии на обучающей выборке = 0.7613597648824619\n"
     ]
    }
   ],
   "source": [
    "print('F1 метрика логистической регрессии на обучающей выборке =', grid_lr.best_score_)\n",
    "#f1_lr = grid_lr.best_params_.round(2)\n",
    "# расчет F1 меры для модели Логистическая регрессия\n",
    "#print('F1 метрика логистической регрессии на обучающей выборке =', f1_lr)\n",
    "\n",
    "# добавление результата в итоговую таблицу\n",
    "results = results.append({'model': 'LogisticRegression', 'F1 (train)': grid_lr.best_score_.round(2)}, \n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем RandomizedSearchCV для подбора гиперпараметров для модели Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree = Pipeline(\n",
    "    [\n",
    "        #('vect', TfidfVectorizer())\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', DecisionTreeClassifier(random_state=12345))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# диапоазон параметров для поиска наилучшего\n",
    "params = {'clf__max_depth':np.arange(5,56,10),\n",
    "          'clf__min_samples_leaf':np.arange(2,15,4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск наилучших параметров\n",
    "search = RandomizedSearchCV(estimator=pipe_tree, param_distributions=params, cv=3, \n",
    "                            scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие гиперпараметры модели: Pipeline(steps=[('tfidf', TfidfTransformer()),\n",
      "                ('clf',\n",
      "                 DecisionTreeClassifier(max_depth=55, min_samples_leaf=10,\n",
      "                                        random_state=12345))])\n",
      "CPU times: user 11min 20s, sys: 4.23 s, total: 11min 25s\n",
      "Wall time: 12min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(tfidf_train, target_train)\n",
    "print('Наилучшие гиперпараметры модели:', search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика решающего дерева на обучающей выборке = 0.7\n"
     ]
    }
   ],
   "source": [
    "print('F1 метрика решающего дерева на обучающей выборке =', search.best_score_.round(2))\n",
    "\n",
    "# добавление результата в итоговую таблицу\n",
    "results = results.append({'model': 'DecisionTreeClassifier', 'F1 (train)': search.best_score_.round(2)}, \n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение модели\n",
    "cat.fit(tfidf_train, target_train, verbose=False) \n",
    "\n",
    "predict_train_cat = cat.predict(tfidf_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика CatBoostClassifier на обучающей выборке = 0.79\n"
     ]
    }
   ],
   "source": [
    "f1_cat = f1_score(target_train, predict_train_cat).round(2)\n",
    "print('F1 метрика CatBoostClassifier на обучающей выборке =', f1_cat)\n",
    "\n",
    "# добавление результата в итоговую таблицу\n",
    "results = results.append({'model': 'CatBoostClassifier', 'F1 (train)': f1_cat}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>F1 (train)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  F1 (train)\n",
       "0      LogisticRegression        0.76\n",
       "1  DecisionTreeClassifier        0.70\n",
       "2      CatBoostClassifier        0.79"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим f1 метрики на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика логистической регрессии на тестовой выборке = 0.76\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "lr_test = LogisticRegression(C=10, class_weight='balanced', max_iter=50, solver='liblinear', \n",
    "                             random_state=12345)\n",
    "lr_test.fit(tfidf_train, target_train)\n",
    "predict_test_lr = lr_test.predict(tfidf_test)\n",
    "# расчет F1 меры для модели Логистическая регрессия\n",
    "f1_test_lr = f1_score(target_test, predict_test_lr).round(2)\n",
    "print('F1 метрика логистической регрессии на тестовой выборке =', f1_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика Решающее дерево на тестовой выборке = 0.7\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "tree_test = DecisionTreeClassifier(max_depth=45, min_samples_leaf=2, random_state=12345)\n",
    "tree_test.fit(tfidf_train, target_train)\n",
    "predict_test_tree = tree_test.predict(tfidf_test)\n",
    "# расчет F1 меры для модели Решающее дерево\n",
    "f1_test_tree = f1_score(target_test, predict_test_tree).round(2)\n",
    "print('F1 метрика Решающее дерево на тестовой выборке =', f1_test_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика CatBoost на тестовой выборке = 0.76\n"
     ]
    }
   ],
   "source": [
    "# CatBoostClassifier\n",
    "predict_test_cat = cat.predict(tfidf_test)\n",
    "# расчет F1 меры для модели CatBoost\n",
    "f1_test_cat = f1_score(target_test, predict_test_cat).round(2)\n",
    "print('F1 метрика CatBoost на тестовой выборке =', f1_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавление результата в итоговую таблицу\n",
    "results['F1_test'] = ['0,76', '0.70', '0.76']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>F1 (train)</th>\n",
       "      <th>F1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0,76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  F1 (train) F1_test\n",
       "0      LogisticRegression        0.76    0,76\n",
       "1  DecisionTreeClassifier        0.70    0.70\n",
       "2      CatBoostClassifier        0.79    0.76"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрели три модели для сравнения метрик.\n",
    "  \n",
    "На тестовой выборке значение F1 метрики (выше 0.75) достигло только у моделей LogisticRegression и CatBoostClassifier. Модель DecisionTreeClassifier совсем не справилась с поставленной задачей, даже с подбором наилучших гиперпарамтеров. Наилучший результат показала модель CatBoostClassifier.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1544,
    "start_time": "2022-08-20T21:22:21.371Z"
   },
   {
    "duration": 230,
    "start_time": "2022-08-20T21:24:05.036Z"
   },
   {
    "duration": 294,
    "start_time": "2022-08-20T21:24:30.326Z"
   },
   {
    "duration": 2705,
    "start_time": "2022-08-20T21:25:44.590Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-20T21:26:16.894Z"
   },
   {
    "duration": 52930,
    "start_time": "2022-08-21T12:06:18.565Z"
   },
   {
    "duration": 2180,
    "start_time": "2022-08-21T12:07:11.497Z"
   },
   {
    "duration": 1810,
    "start_time": "2022-08-21T12:07:13.678Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-21T12:07:15.490Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-21T12:45:23.968Z"
   },
   {
    "duration": 761,
    "start_time": "2022-08-24T18:54:42.026Z"
   },
   {
    "duration": 81956,
    "start_time": "2022-08-24T18:54:42.790Z"
   },
   {
    "duration": 2223,
    "start_time": "2022-08-24T18:56:04.747Z"
   },
   {
    "duration": 35,
    "start_time": "2022-08-24T18:56:06.972Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-24T18:56:07.009Z"
   },
   {
    "duration": 2143,
    "start_time": "2022-08-24T18:56:07.013Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-24T18:56:09.158Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-24T18:56:09.169Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-24T18:56:09.186Z"
   },
   {
    "duration": 3553,
    "start_time": "2022-08-24T18:56:09.195Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-24T18:56:12.750Z"
   },
   {
    "duration": 544,
    "start_time": "2022-08-24T18:56:12.759Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-24T18:56:13.305Z"
   },
   {
    "duration": 625689,
    "start_time": "2022-08-24T18:56:13.311Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-24T19:06:39.002Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-24T19:06:39.013Z"
   },
   {
    "duration": 78,
    "start_time": "2022-08-24T19:06:39.023Z"
   },
   {
    "duration": 25,
    "start_time": "2022-08-24T19:06:39.103Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-24T19:06:39.130Z"
   },
   {
    "duration": 4150,
    "start_time": "2022-08-24T19:06:39.138Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-24T19:06:43.290Z"
   },
   {
    "duration": 8714,
    "start_time": "2022-08-24T19:06:43.294Z"
   },
   {
    "duration": 30,
    "start_time": "2022-08-24T19:06:52.010Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-24T19:13:02.994Z"
   },
   {
    "duration": 204653,
    "start_time": "2022-08-24T19:13:03.760Z"
   },
   {
    "duration": 29,
    "start_time": "2022-08-24T19:27:37.557Z"
   },
   {
    "duration": 20,
    "start_time": "2022-08-24T19:29:49.782Z"
   },
   {
    "duration": 17136,
    "start_time": "2022-08-24T19:29:50.661Z"
   },
   {
    "duration": 410,
    "start_time": "2022-08-24T19:35:20.658Z"
   },
   {
    "duration": 300,
    "start_time": "2022-08-24T19:35:24.847Z"
   },
   {
    "duration": 53,
    "start_time": "2022-08-24T20:20:34.854Z"
   },
   {
    "duration": 735,
    "start_time": "2022-08-24T20:20:47.144Z"
   },
   {
    "duration": 64419,
    "start_time": "2022-08-24T20:21:06.531Z"
   },
   {
    "duration": 2473,
    "start_time": "2022-08-24T20:22:10.953Z"
   },
   {
    "duration": 48,
    "start_time": "2022-08-24T20:22:13.429Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-24T20:23:09.764Z"
   },
   {
    "duration": 2671,
    "start_time": "2022-08-24T20:23:10.680Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-24T20:23:13.352Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-24T20:23:16.205Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-24T20:23:17.445Z"
   },
   {
    "duration": 3782,
    "start_time": "2022-08-24T20:23:18.793Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-24T20:23:22.577Z"
   },
   {
    "duration": 539,
    "start_time": "2022-08-24T20:23:24.595Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-24T20:23:25.395Z"
   },
   {
    "duration": 612250,
    "start_time": "2022-08-24T20:23:26.492Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-24T20:33:38.744Z"
   },
   {
    "duration": 55,
    "start_time": "2022-08-24T20:33:38.753Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-24T20:49:06.220Z"
   },
   {
    "duration": 28,
    "start_time": "2022-08-24T20:49:07.076Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-24T20:49:08.867Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-24T20:49:17.126Z"
   },
   {
    "duration": 4093,
    "start_time": "2022-08-24T20:49:17.812Z"
   },
   {
    "duration": 56,
    "start_time": "2022-08-25T07:40:21.477Z"
   },
   {
    "duration": 115771,
    "start_time": "2022-08-25T07:40:41.843Z"
   },
   {
    "duration": 3449,
    "start_time": "2022-08-25T07:42:37.616Z"
   },
   {
    "duration": 44,
    "start_time": "2022-08-25T07:42:41.066Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-25T07:42:41.112Z"
   },
   {
    "duration": 2665,
    "start_time": "2022-08-25T07:42:41.118Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-25T07:42:43.785Z"
   },
   {
    "duration": 22,
    "start_time": "2022-08-25T07:42:43.798Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-25T07:42:43.822Z"
   },
   {
    "duration": 3990,
    "start_time": "2022-08-25T07:42:43.830Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-25T07:42:47.823Z"
   },
   {
    "duration": 620,
    "start_time": "2022-08-25T07:42:47.833Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T07:42:48.455Z"
   },
   {
    "duration": 738189,
    "start_time": "2022-08-25T07:42:48.460Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-25T07:55:06.651Z"
   },
   {
    "duration": 72,
    "start_time": "2022-08-25T07:55:06.664Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-25T08:43:35.833Z"
   },
   {
    "duration": 313,
    "start_time": "2022-08-25T09:46:18.822Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-25T09:46:42.992Z"
   },
   {
    "duration": 25,
    "start_time": "2022-08-25T09:46:45.812Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-25T09:46:49.059Z"
   },
   {
    "duration": 50923,
    "start_time": "2022-08-25T09:46:55.576Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T09:55:55.912Z"
   },
   {
    "duration": 4920,
    "start_time": "2022-08-25T09:55:56.583Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T09:57:43.642Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T09:57:46.931Z"
   },
   {
    "duration": 291306,
    "start_time": "2022-08-25T09:57:57.622Z"
   },
   {
    "duration": 36,
    "start_time": "2022-08-25T10:02:48.930Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-25T10:33:21.654Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-25T10:35:36.600Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-25T10:35:43.096Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T10:35:47.192Z"
   },
   {
    "duration": 249912,
    "start_time": "2022-08-25T10:35:49.764Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-25T10:39:59.677Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T11:14:27.887Z"
   },
   {
    "duration": 320027,
    "start_time": "2022-08-25T11:14:28.687Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-25T11:19:48.716Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T11:22:35.482Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-25T11:22:38.574Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-25T11:22:38.950Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T11:22:42.094Z"
   },
   {
    "duration": 337581,
    "start_time": "2022-08-25T11:22:44.476Z"
   },
   {
    "duration": 77,
    "start_time": "2022-08-25T11:28:22.059Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-25T11:29:39.525Z"
   },
   {
    "duration": 26,
    "start_time": "2022-08-25T11:31:55.616Z"
   },
   {
    "duration": 25,
    "start_time": "2022-08-25T11:33:13.299Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-25T11:33:49.331Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-25T11:36:39.979Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-25T11:36:59.215Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T11:37:02.978Z"
   },
   {
    "duration": 222032,
    "start_time": "2022-08-25T11:37:03.319Z"
   },
   {
    "duration": 43,
    "start_time": "2022-08-25T11:40:45.353Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-25T11:40:45.398Z"
   },
   {
    "duration": 25291,
    "start_time": "2022-08-25T11:42:01.836Z"
   },
   {
    "duration": 23378,
    "start_time": "2022-08-25T11:43:37.804Z"
   },
   {
    "duration": 468,
    "start_time": "2022-08-25T11:44:01.183Z"
   },
   {
    "duration": 22,
    "start_time": "2022-08-25T11:44:13.717Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-25T11:44:22.224Z"
   },
   {
    "duration": 792,
    "start_time": "2022-08-25T16:42:19.316Z"
   },
   {
    "duration": 90966,
    "start_time": "2022-08-25T16:42:20.110Z"
   },
   {
    "duration": 2720,
    "start_time": "2022-08-25T16:43:51.077Z"
   },
   {
    "duration": 44,
    "start_time": "2022-08-25T16:43:53.800Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T16:43:53.845Z"
   },
   {
    "duration": 2283,
    "start_time": "2022-08-25T16:43:53.850Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-25T16:43:56.135Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-25T16:43:56.145Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-25T16:43:56.155Z"
   },
   {
    "duration": 3582,
    "start_time": "2022-08-25T16:43:56.163Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-25T16:43:59.746Z"
   },
   {
    "duration": 699,
    "start_time": "2022-08-25T16:43:59.756Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-25T16:44:00.457Z"
   },
   {
    "duration": 657425,
    "start_time": "2022-08-25T16:44:00.462Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-25T16:54:57.889Z"
   },
   {
    "duration": 51,
    "start_time": "2022-08-25T16:54:57.904Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-25T16:54:57.957Z"
   },
   {
    "duration": 27,
    "start_time": "2022-08-25T16:54:57.985Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-25T16:54:58.013Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-25T16:54:58.019Z"
   },
   {
    "duration": 4616,
    "start_time": "2022-08-25T16:54:58.031Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-25T16:55:02.648Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-25T16:55:02.653Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-25T16:55:02.668Z"
   },
   {
    "duration": 336429,
    "start_time": "2022-08-25T16:55:02.687Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-25T17:00:39.117Z"
   },
   {
    "duration": 1287,
    "start_time": "2022-08-25T17:04:54.704Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
